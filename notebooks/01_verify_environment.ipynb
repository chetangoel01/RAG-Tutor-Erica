{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erica AI Tutor - Environment Verification\n",
    "\n",
    "This notebook verifies that all services are running correctly.\n",
    "\n",
    "**Your Setup:**\n",
    "- MacBook M1 Pro\n",
    "- OpenRouter API for LLM (Qwen2.5)\n",
    "- Docker containers for databases\n",
    "\n",
    "Run each cell to check connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded\n",
      "  OpenRouter Model: qwen/qwen-2.5-72b-instruct\n",
      "  API Key Set: Yes\n",
      "  Neo4j URI: bolt://neo4j:7687\n",
      "  ChromaDB: http://chromadb:8000\n"
     ]
    }
   ],
   "source": [
    "# Add src to path\n",
    "import sys\n",
    "sys.path.insert(0, '/app/src')\n",
    "\n",
    "from config import settings\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"  OpenRouter Model: {settings.openrouter_model}\")\n",
    "print(f\"  API Key Set: {'Yes' if settings.openrouter_api_key else 'NO - Please set OPENROUTER_API_KEY in .env'}\")\n",
    "print(f\"  Neo4j URI: {settings.neo4j_uri}\")\n",
    "print(f\"  ChromaDB: {settings.chroma_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test OpenRouter API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Qwen models on OpenRouter:\n",
      "  qwen2.5-72b: qwen/qwen-2.5-72b-instruct\n",
      "  qwen2.5-32b: qwen/qwen-2.5-32b-instruct\n",
      "  qwen2.5-14b: qwen/qwen-2.5-14b-instruct\n",
      "  qwen2.5-7b: qwen/qwen-2.5-7b-instruct\n",
      "  qwen2.5-coder-32b: qwen/qwen-2.5-coder-32b-instruct\n",
      "\n",
      "OK: OpenRouter API working\n",
      "  Model: qwen/qwen-2.5-72b-instruct\n",
      "  Test response: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm import LLMClient, AVAILABLE_MODELS\n",
    "\n",
    "def test_openrouter():\n",
    "    if not settings.openrouter_api_key:\n",
    "        print(\"FAIL: OpenRouter API key not set\")\n",
    "        print(\"  1. Get your key at: https://openrouter.ai/keys\")\n",
    "        print(\"  2. Add to .env: OPENROUTER_API_KEY=sk-or-v1-your-key\")\n",
    "        print(\"  3. Restart the container: docker-compose restart app\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        client = LLMClient()\n",
    "        response = client.generate(\n",
    "            \"What is 2+2? Reply with just the number.\",\n",
    "            temperature=0\n",
    "        )\n",
    "        print(\"OK: OpenRouter API working\")\n",
    "        print(f\"  Model: {settings.openrouter_model}\")\n",
    "        print(f\"  Test response: {response.strip()}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: OpenRouter API error: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"Available Qwen models on OpenRouter:\")\n",
    "for name, model_id in AVAILABLE_MODELS.items():\n",
    "    print(f\"  {name}: {model_id}\")\n",
    "print()\n",
    "\n",
    "test_openrouter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Neo4j Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Neo4j is running\n",
      "  Browser UI: http://localhost:7474\n",
      "  Login: neo4j / erica_password_123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "def test_neo4j():\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(\n",
    "            settings.neo4j_uri,\n",
    "            auth=(settings.neo4j_user, settings.neo4j_password)\n",
    "        )\n",
    "        with driver.session() as session:\n",
    "            result = session.run(\"RETURN 1 as n\")\n",
    "            result.single()\n",
    "        driver.close()\n",
    "        print(\"OK: Neo4j is running\")\n",
    "        print(f\"  Browser UI: http://localhost:7474\")\n",
    "        print(f\"  Login: neo4j / erica_password_123\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Cannot connect to Neo4j: {e}\")\n",
    "        print(\"  Make sure the neo4j container is running: docker-compose up -d neo4j\")\n",
    "    return False\n",
    "\n",
    "test_neo4j()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test ChromaDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: ChromaDB is running\n",
      "  Collections: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "def test_chromadb():\n",
    "    try:\n",
    "        client = chromadb.HttpClient(\n",
    "            host=settings.chroma_host,\n",
    "            port=settings.chroma_port\n",
    "        )\n",
    "        # Try to list collections\n",
    "        collections = client.list_collections()\n",
    "        print(\"OK: ChromaDB is running\")\n",
    "        print(f\"  Collections: {len(collections)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Cannot connect to ChromaDB: {e}\")\n",
    "        print(\"  Make sure the chromadb container is running: docker-compose up -d chromadb\")\n",
    "    return False\n",
    "\n",
    "test_chromadb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test MongoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: MongoDB is running\n",
      "  Database: erica_tutor\n",
      "  Web UI: http://localhost:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "def test_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(settings.mongodb_uri, serverSelectionTimeoutMS=5000)\n",
    "        # Force connection\n",
    "        client.server_info()\n",
    "        db = client[settings.mongodb_database]\n",
    "        print(\"OK: MongoDB is running\")\n",
    "        print(f\"  Database: {settings.mongodb_database}\")\n",
    "        print(f\"  Web UI: http://localhost:8081\")\n",
    "        client.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Cannot connect to MongoDB: {e}\")\n",
    "        print(\"  Make sure the mongodb container is running: docker-compose up -d mongodb\")\n",
    "    return False\n",
    "\n",
    "test_mongodb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5c64ad42004d00853a5d72b4f2411f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb5484b83e0466683d4fc86eef3376a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea0986243eb4b7c82017a66b7cb7362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72d995e2b2a4773a5adb1ab17d6c367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92097a1f42b480ea30f178ce128a653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac08f30d1b5436ea74cddef5145ac9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44669b8fa474c87a4638f1a815dce49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11871d2f1dd4d4da836c484e324bf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ad912bb7434028b206d944d51abaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531a1eb7d95347d6afe038be284c3f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c161b045c81143b48d228d20b0d2c28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Embedding model loaded\n",
      "  Model: all-MiniLM-L6-v2\n",
      "  Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def test_embeddings():\n",
    "    try:\n",
    "        print(f\"Loading embedding model: {settings.embedding_model}...\")\n",
    "        model = SentenceTransformer(settings.embedding_model)\n",
    "        test_text = \"Introduction to Artificial Intelligence\"\n",
    "        embedding = model.encode(test_text)\n",
    "        print(\"OK: Embedding model loaded\")\n",
    "        print(f\"  Model: {settings.embedding_model}\")\n",
    "        print(f\"  Embedding dimension: {len(embedding)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Cannot load embedding model: {e}\")\n",
    "    return False\n",
    "\n",
    "test_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Entity Extraction (LLM + Structured Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing entity extraction (this calls the LLM)...\n",
      "OK: Entity extraction working\n",
      "  Entities found: 6\n",
      "  Relationships found: 5\n",
      "\n",
      "  Sample entities:\n",
      "    - Machine learning (concept)\n",
      "    - Supervised learning (concept)\n",
      "    - Unsupervised learning (concept)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_entity_extraction():\n",
    "    \"\"\"Test that we can extract entities - crucial for M3 (Knowledge Graph).\"\"\"\n",
    "    if not settings.openrouter_api_key:\n",
    "        print(\"SKIP: OpenRouter not configured\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        from llm import LLMClient\n",
    "        client = LLMClient()\n",
    "        \n",
    "        sample_text = \"\"\"\n",
    "        Machine learning is a subset of artificial intelligence that enables \n",
    "        systems to learn from data. Supervised learning requires labeled data, \n",
    "        while unsupervised learning finds patterns without labels. \n",
    "        Neural networks are a key technique in deep learning.\n",
    "        \"\"\"\n",
    "        \n",
    "        result = client.extract_entities(sample_text)\n",
    "        \n",
    "        print(\"OK: Entity extraction working\")\n",
    "        print(f\"  Entities found: {len(result.get('entities', []))}\")\n",
    "        print(f\"  Relationships found: {len(result.get('relationships', []))}\")\n",
    "        \n",
    "        if result.get('entities'):\n",
    "            print(\"\\n  Sample entities:\")\n",
    "            for ent in result['entities'][:3]:\n",
    "                print(f\"    - {ent.get('name', 'N/A')} ({ent.get('type', 'N/A')})\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Entity extraction failed: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"Testing entity extraction (this calls the LLM)...\")\n",
    "test_entity_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ENVIRONMENT VERIFICATION SUMMARY\n",
      "==================================================\n",
      "\n",
      "OK: OpenRouter API working\n",
      "  Model: qwen/qwen-2.5-72b-instruct\n",
      "  Test response: 4\n",
      "OK: Neo4j is running\n",
      "  Browser UI: http://localhost:7474\n",
      "  Login: neo4j / erica_password_123\n",
      "OK: ChromaDB is running\n",
      "  Collections: 0\n",
      "OK: MongoDB is running\n",
      "  Database: erica_tutor\n",
      "  Web UI: http://localhost:8081\n",
      "Loading embedding model: all-MiniLM-L6-v2...\n",
      "OK: Embedding model loaded\n",
      "  Model: all-MiniLM-L6-v2\n",
      "  Embedding dimension: 384\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "SUCCESS: All services are running! You are ready for M2 (Ingestion).\n",
      "\n",
      "Next steps:\n",
      "  1. Open notebooks/01_ingestion.ipynb\n",
      "  2. Start ingesting course content\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENVIRONMENT VERIFICATION SUMMARY\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "results = {\n",
    "    \"OpenRouter (LLM)\": test_openrouter(),\n",
    "    \"Neo4j (Graph DB)\": test_neo4j(),\n",
    "    \"ChromaDB (Vector DB)\": test_chromadb(),\n",
    "    \"MongoDB (Document Store)\": test_mongodb(),\n",
    "    \"Embeddings\": test_embeddings()\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "all_pass = all(results.values())\n",
    "if all_pass:\n",
    "    print(\"\\nSUCCESS: All services are running! You are ready for M2 (Ingestion).\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Open notebooks/01_ingestion.ipynb\")\n",
    "    print(\"  2. Start ingesting course content\")\n",
    "else:\n",
    "    failed = [k for k, v in results.items() if not v]\n",
    "    print(f\"\\nWARNING: Some services failed: {failed}\")\n",
    "    print(\"  Fix these before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### OpenRouter Issues\n",
    "```bash\n",
    "# Check your API key is set\n",
    "grep OPENROUTER .env\n",
    "\n",
    "# Restart container after changing .env\n",
    "docker-compose restart app\n",
    "```\n",
    "\n",
    "### Container Issues (Mac M1)\n",
    "```bash\n",
    "# Check container status\n",
    "docker-compose ps\n",
    "\n",
    "# View logs for a specific service\n",
    "docker-compose logs neo4j\n",
    "docker-compose logs chromadb\n",
    "\n",
    "# Restart all containers\n",
    "docker-compose down && docker-compose up -d\n",
    "```\n",
    "\n",
    "### Memory Issues on Mac\n",
    "- Increase Docker Desktop memory allocation (Settings > Resources)\n",
    "- Recommended: 8GB+ for all services"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
